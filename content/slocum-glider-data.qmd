---
title: Slocum Glider Data
---

There are many steps and flavors to slocum glider data processing (hereafter 'glider data processing'), from the base processing (binary files to NetCDF for Slocum gliders), to QA/QC, to developing additional data products. This page outlines the ESD glider lab's data processing workflow, in particular base processing and data products. 

Users interested in understanding and accessing data products created for each deployment should see the [Data Products](#data-products) section. For acoustic or image processing workflows, see the [acoustics](active-acoustics.qmd) and [imagery](imagery.qmd) pages, respectively.

## Background

Historically, the ESD glider team processed glider data using the Matlab toolbox [`SOCIB`](https://github.com/socib/glider_toolbox). However, this toolbox is not actively maintained, and the majority of ESD processing efforts have moved to Google Cloud (GCP), an environment where Matlab is difficult to run. Subsequent efforts involved developing [`amlr-gliders`](https://github.com/us-amlr/amlr-gliders), a Python toolbox and scripts that were primarily wrappers around [`gdm`](https://github.com/kerfoot/gdm). These efforts never caught full traction.

Currently, the ESD glider lab uses the `esdglider` Python toolbox and scripts, which can be found in the [`esdglider`](https://github.com/SWFSC/esdglider) repo, to do its base glider data processing. `esdglider` primarily consists of ESD-specific wrappers around existing toolboxes such as [`PyGlider`](https://pyglider.readthedocs.io/en/latest/), [`GliderTools`](https://glidertools.readthedocs.io/en/latest/), and [`dbdreader`](https://dbdreader.readthedocs.io/en/latest/). All efforts are geared towards processing ESD glider data in ESD's Google Cloud project, using an [Open Science approach](https://openscapes.org/).

<!-- Todo: create and add flow chart, a la [here](https://github.com/SAEL-SWFSC/SAEL-lab-manual/blob/main/content/images/FOSSA.JPG) -->

### Terminology

Common terminology used in glider data processing:

* glider-YYYYmmdd: The deployment name, e.g. amlr01-20181201 for glider amlr01, deployed on 1 Dec 2018. 
* mode: the mode of glider data acquisition, either real-time ('rt', ) or delayed-mode ('delayed'). The delayed data is the full resolution dataset , which can be downloaded from the glider only after the glider has been recovered. The rt data is a subset of the full-resolution data from the delayed mode, that has been transmitted via Iridium while the glider is deployed.
* [Profile, and other sampling terminology](https://ioos.github.io/glider-dac/glider-background-and-sampling-terminology.html#sampling-pattern-terminology)
* [NetCDF](https://docs.unidata.ucar.edu/netcdf-c/current/)
* inflection: when a glider is transitioning from a dive to a climb, or from a climb to a dive
* [OG1.0 controlled vocabulary](https://oceangliderscommunity.github.io/OG-format-user-manual/vocabularyCollection/tableOfControlledVocab.html) (also see [OG1.0 background](https://oceangliderscommunity.github.io/OG-format-user-manual/OG_Format.html))

## Base Processing

The base glider data processing, also referred to as "Level 1" or "L1" processing, is primarily done using [`PyGlider`](https://pyglider.readthedocs.io/en/latest/), hereafter simply `pyglider`. `pyglider` creates CF-compliant timeseries and gridded NetCDF files, which can be both used internally in further workflows, as well as made publicly available through an ERDDAP (e.g., via the [IOOS Glider DAC](https://gliders.ioos.us/)). 

These base processing details apply to both real-time and delayed-mode data. 

### Overview

The current high-level workflow is shown below. For more in-the-weeds details, see the relevant sections below. See [data products](#data-products) for a description of the output files. 

![ESD's base glider data processing](images/base-proc-workflow.jpg){fig-align="left"}

1. Upload all deployment files as specified on the [data management page](data-management.qmd#deployments). 
2. Create a deployment YAML file, and commit the edited file to the [glider-lab repo](https://github.com/SWFSC/glider-lab/tree/main/deployment-configs).
3. Create a [deployment-specific processing script](https://github.com/SWFSC/glider-lab/tree/main/deployment-scripts), and run it in a GCP Workbench Instance top create data products.
4. Access processed NetCDF files via GCP for additional internal workflows. 
5. (in development) serve/archive data with IOOS/NCEI. 

#### binary_to_nc

The `binary_to_nc` function is the workhorse of the `esdglider` base processing for Slocum gliders. This function is described in-depth in the [Timeseries](#timeseries) and [Gridded](#gridded) sections. 

![esdglider's `binary_to_nc` inputs, outputs, and top-level helper functions](images/binary_to_nc.JPG){fig-align="left"}

#### deployment YAML files

Like `pyglider`, `esdglider` relies on deployment YAML files (i.e., deployment configs) for all metadata related to a glider deployment. These files contain information such as [metadata required by IOOS](https://ioos.github.io/glider-dac/ngdac-netcdf-file-format-version-2.html), what devices were on the glider and when they were last calibrated, and the data (i.e., sensor names) to extract from the binary data. See the [pyglider docs](https://pyglider.readthedocs.io/en/latest/getting-started-slocum.html#make-a-deployment-configuration-file) for more details about the deployment YAML file.

To help generate these files, `esdglider` contains [this script](https://github.com/SWFSC/esdglider/blob/main/scripts/generate-deployment_yaml.py) that can be run locally (i.e., wherever it can access the database) to create a deployment YAML file. This script pulls all instrument information from the Glider Database, and adds standard metadata. A user needs to then edit this file by hand, in particular the people, devices, comment, and summary blocks. Deployment YAMLs for all ESD glider deployments are stored in the [glider-lab repo](https://github.com/SWFSC/glider-lab/tree/main/deployment-configs).

#### deployment processing scripts

All base processing is performed by deployment-specific Python processing scripts, which can also be found in the [glider-lab repo](https://github.com/SWFSC/glider-lab/tree/main/deployment-scripts). These scripts create NetCDF files, acoustic data procucts (if necessary), imagery data products (if necessary), and standard plots. A template script 'glider-YYYYmmdd-template.py' for a new deployment can be found in the same glider-lab repo folder. For a new script, users can update the 'deployment_name' and 'mode' variables, and uncomment base processing sections that are relevant for that deployment.

Deployment scripts are designed to be run in GCP, so that they are able to access data stored in the GCS buckets. Currently, they are all run in the 'glider-proc' GCP Workbench Instance. 

### Data Products

The `esdglider` toolbox heavily leverages `dbdreader` and `pyglider` to create several different base processing data products, which are described in this section. For descriptions of the various standard plots, see the [Plots](#plots) section. See the individual base processing sections for specific processing steps, choices, etc.

All output files begin with the deployment name ('glider-YYYYmmdd'), and include the data processing 'mode' (i.e., delayed or rt). The timeseries data products are all NetCDF files with a single coordinate "time". The gridded data products are all NetCDF files with two coordinates: "depth" and "profile" (i.e., profile_index). An exception is a 'profiles' CSV, which contains the start/end times, depths, and other info for each profile.

Standard data products:

- **science timeseries:** {glider-YYYYmmdd}-{mode}-sci.nc: The 'science' timeseries. Most users will want this dataset, as it contains the values from all of the various science sensors. Functionally speaking, this timeseries has one ‘row’ of data for each timestamp from the glider’s *science* computer where a CTD temperature value was recorded. All included sensor values are interpolated to all timestamps, as long as there is not a gap of 300 or more seconds. The sensor values included in this dataset depend on the instruments carried by the glider; ... (Todo: add a section that lists the sensor values for each instrument). Users should note that the 'depth' value in this timeseries is the depth calculated from the CTD pressure sensor. 

- **science gridded 5m:** {glider-YYYYmmdd}_grid-{mode}-5m.nc: The science timeseries, gridded into *five* meter bins. This NetCDF file will include all of the science sensor values that were in the science timeseries. Users should note that the depth bin name is the bin midpoint. For instance, the bin for data from zero to five meters has the name/label "2.5".

- **images+science timeseries:** {glider-YYYYmmdd}-imagery-metadata.csv: A CSV file with one row for each image, and one column for each desired sensor value. The sensor values are interpolated to each image timestamp. This file is only created if the glider is carrying a camera, such as a shadowgraph or glidercam. Note that this file lives in the raw glider imagery bucket (e.g. [here](https://console.cloud.google.com/storage/browser/amlr-gliders-imagery-raw-dev/SANDIEGO/2022/amlr08-20220513/metadata))

Additional data products:

- **raw timeseries:** {glider-YYYYmmdd}-{mode}-raw.nc: The 'raw' timeseries is the unprocess data, simply read from the binary data files and saved as a NetCDF. Itcontains a timestamp for every time recorded by the glider's flight or science computer, and no interpolation is done for any sensor values. These two features make this dataset useful for a) calculating profiles and b) troubleshooting any sensor values or processing steps. This dataset contains both the measured depth ("depth_measured") and the depth calculated from the CTD pressure sensor ("depth_ctd"). 

- **engineering timeseries:** {glider-YYYYmmdd}-{mode}-eng.nc: The 'engineering' timeseries. Functionally speaking, this timeseries has one 'row' of data for each timestamp from the glider's *flight* computer where an m_depth value was recorded. All included sensor values are interpolated to all timestamps, as long as there is not a gap of 300 or more seconds. In addition to m_depth, it contains sensor values such as m_roll, m_pitch, and m_gps_lon. See the full list of sensor values [here](https://github.com/SWFSC/esdglider/blob/main/esdglider/data/deployment-eng-vars.yml). Users should note that the 'depth' value in this timeseries is from m_depth, meaning the measured depth from the glider.

- **profile summary:** {glider-YYYYmmdd}-{mode}-profiles.csv: A CSV file with one row for each profile, containing information such as: profile index, profile start and end time, profile start and end depth, and profile direction. Note that this file contains "#.5" profiles, which mark the time between profiles (e.g., when the glider is at the surface or inflecting).

- **science gridded 1m:** {glider-YYYYmmdd}_grid-{mode}-1m.nc: The science timeseries, gridded into *one* meter bins. This NetCDF file will include all of the science sensor values that were in the science timeseries. Users should note that the depth bin name is the bin midpoint. For instance, the bin for data from zero to one meters has the name/label "0.5".

- **acoustic metadata files**: Files needed for processing acoustic data with Echoview. These files are described on the [acoustics](active-acoustics.qmd) page. These files are only created if the glider is carrying an acoustic instrument, such as a Nortek or AZFP.

### Timeseries

This section describes in-the-weeds details of and choices choices made by the code when using the binary slocum glider files to generate timeseries files. See [data products](#data-products) for a description of the timeseries output files. 

The `pyglider.slocum.binary_to_timeseries` function uses [`dbdreader`](https://dbdreader.readthedocs.io/en/latest/) to read slocum glider data from binary files. More discussion can be found [here](https://github.com/c-proof/pyglider/issues/106) around why `pyglider` switched to using `dbdreader`, and how `pyglider` processing worked before. Many `pyglider` functions, including `binary_to_timeseries`, rely on a [yaml deployment configuration file](#deployment-yaml-files) for e.g. metadata and mapping sensor names to NetCDF variable names. 

As constructed, `binary_to_timeseries` uses [`dbdreader.get_sync`](https://dbdreader.readthedocs.io/en/latest/multiple_files.html#dbdreader.MultiDBD.get_sync) to extract values for all of the specified sensors. Specifically, the user specifies a particular sensor to server as the 'time_base', and then all other desired variables (across science and engineering, e.g. pressure, temperature, oxygen, roll) are interpolated onto the same timestamps. These timestamps are where this 'time_base' variable has a valid (i.e., not missing or nan) value. However, no interpolation is done for the science variables if the gap between time points is greater than or equal to 'maxgap' seconds. Comprehensive interpolation always happens for the engineering variables. Within ESD, we use a maxgap of 60 seconds.

#### raw 

There is no way to use `binary_to_timeseries` to generate the raw timeseries. For this, we use the `esdglider` function `binary_to_raw_timeseries` - this function follows the same general logic as `pyglider`'s `binary_to_timeseries`, except that it uses another `dbdreader` function ([`get`](https://dbdreader.readthedocs.io/en/latest/multiple_files.html#dbdreader.MultiDBD.get), with `return_nans=True`) to extract all recorded timestamps across the specified variables. Thus, there are functionally two 'time bases' for the extracted data: one for engineering variables (from the flight computer's 'm_present_time'), and one for science variables (from the science computer's 'sci_m_present_time'). These timestamp arrays are merged, and the m,erged array is the time index of the raw timeseries NetCDF file. 

No sensor values are interpolated. Invalid timestamps are still dropped, as well as timestamps that either a) have no non-nan sensor values, and b) came before the 'deployment_min_dt' metadata attribute in the `deployment.yaml` file. Values that are calculated and included in the raw dataset include 'depth_ctd' (the glider depth calculated from the pressure sensor reading) and 'distance_over_ground' (the great-circle distance between each measured lat/lon). 

The raw timeseries contains all glider data points, and is thus particularly useful for debugging code or sensor behavior. It is also used to calculate profiles. Profiles can be difficult to calculate, as sometimes the glider stalls in the water or otherwise has a moment that causes it to for instance briefly go down again when it is on a climb back to the surface. To robustly find profiles in the dataset, `esdglider` uses the raw glider measured depth (i.e., sensor m_depth from the glider's pressure transducer) and the `findProfiles` function from the [PGPT toolbox](https://github.com/OceanGNS/PGPT/blob/main/scripts/gliderfuncs.py#L196). This is a Pythonic reproduction of a [function of the same name](https://github.com/socib/glider_toolbox/blob/master/m/processing_tools/findProfiles.m) from the `SOCIB` toolbox.

#### eng/sci

As 

In ESD, we use `binary_to_timeseries` to create a 'science' timeseries, with the pressure from the CTD as the time base, and an 'engineering' timeseries, with the glider's measured depth as the time base. We also have written a `binary_to_raw` function, which uses [`dbdreader.get`](https://dbdreader.readthedocs.io/en/latest/multiple_files.html#dbdreader.MultiDBD.get) to read in raw (i.e., uninterpolated) data points from both the science and flight computers. Thus 'raw' timeseries contains all glider data points, and is thus used to calculate profiles, and useful for debugging sensor behavior.

Data alterations, or additional features of note:

`esdglider`:

- min_dt: esdglider allows users to pass a minimum datetime, which is used to filter all glider data for timestamps after this datetime. The datetime is usually when the glider begins its first 1k_n.mi mission.Because pressure is used as the time base for the science dataset, rows in science where pressure is nan are dropped (even if other sensors have non-nan values)

`dbdreader`:

- `dbdreader` throws an warning if a sensor is turned off and thus not present in some sbd/tbd or dbd/ebd files. See [this issue](https://github.com/smerckel/dbdreader/issues/26) for more discussion. 
- `dbdreader` by default skips the first line of each binary file. The reasoning is that “this line contains either nonsense values, or values that were read a long time ago. This behavior can be changed.” See [this issue](https://github.com/smerckel/dbdreader/issues/18) for more discussion. 
- `dbdreader` only identifies sensors as 'engineering' or 'science'. Thus, when extracting e.g. data for the sensor 'sci_oxy4_oxygen', `dbdreader` uses the 'sci_m_present_time' as the timestamp, rather than 'sci_oxy4_present_time'.

`pyglider`: 

- Latitude and longitude values are set to nan if their absolute value is greater than 90 and 180, respectively. 
- Any values of zero from science sensors are converted to nan. 
- No other data alterations/qc are made (e.g., CTD data is all read and left as-is).


### Gridded

This section describes in-the-weeds details of and choices choices made by the code when using the scieince timeseries to generate gridded datasets. See [data products](#data-products) for a description of the gridded output files. 

Docs in progress. Gridding uses the [`pyglider.ncprocess.make_gridfiles`](https://pyglider.readthedocs.io/en/latest/pyglider/pyglider.ncprocess.html#pyglider.ncprocess.make_gridfiles) function.

### Plots

Standard plots are generated from either the 'processed-rt' (subfolder 'rt') or 'processed-L1' data (subfolder 'delayed'). Note that 'sci' is short for plots of science sensor values, while 'eng' is short for plots of engineering variables. Standard plots, which are separated by folder, include:

* TS-sci: Temperature/salinity plots of the various science sensor values
* maps-sci: Maps of surface values (i.e., depth <10m) from various science sensors
* pointMaps: Scatter plots of the lat/lon points recorded by the glider
* spatialGrids-sci: Gridded science data plotted by all combinations of latitude, longitude, and depth
* spatialSections-sci: Gridded science data plotted by either latitude or longitude, and depth
* thisVsThat-eng: Timeseries plots of various engineering sensor values plotted against each other
* timeSections-sci: Gridded science data plotted by time and depth
* timeSections-sci-gt: Gridded science data plotted by profile_index and depth. The plots are made with the `glidertools`[plot module](https://glidertools.readthedocs.io/en/latest/_generated/glidertools.plot.plot_functions.html), and thus use the 0.5 and 99.5 percentile to set color limits.
* timeSeries-eng: Timeseries plots of various engineering sensor values
* timeSeries-sci: Timeseries plots of various science sensor values

### NGDAC Profiles

Docs in progress

### Other Files

Docs in progress

<!-- ESD's base processing also creates several other files necessary for processing or using data from other sensors on the glider. If the glider is carrying a shadowgraph or glidercam camera system, then a CSV file is created that links each image with the relevant glider measurements at that time (depth, temperature, oxygen concentration, etc.). If the glider is carrying an acoustic instrument, specific files are needed to process these data using Echoview. These files are created during the base processing step as well. -->

## Real-Time Data

Currently, all ESD glider data processing is delayed-mode processing. The vision is to have GCP infrastructure in place to:

- Periodically rsync real-time data (sbd/tbd files) from the SFMC to GCP
- Run slocumRtDataVisTool to create plots and statistics useful for real-time piloting decisions 
- Run the base processing steps on these data, and automatically send the processed files to the NGDAC

## Future Directions

QC + data cleaning, to create cleaned netcdf files with qc flags. Potential resources:

- Implement [IOOS QARTOD](https://ioos.noaa.gov/project/qartod/) tests, eg using [ioos_qc](https://github.com/ioos/ioos_qc) to add qc flags
- https://github.com/OceanGlidersCommunity/Realtime-QC
    - https://github.com/castelao/CoTeDe
- other qc/data cleaning? For instance, sanity check ts plots. Likely will involve by-hand inspection for each deployment, including removing bad data if discovered

[GliderTools](https://github.com/GliderToolsCommunity/GliderTools):

- [manuscript](https://doi.org/10.3389/fmars.2019.00738) describing the GliderTools toolbox
- GliderTools contains tools for processing Seaglider basestation files. However, the rest of the tools simply require that the data be in an xarray dataset.
- optics, pq: quenching correction method described by Thomalla et al. (2018)
- additional qc tools?
- calculate cool physics things (mixed layer depth, ...)
- leverage gridded plotting routines

## GitHub Repos

See the [home page](../index.qmd#github-repositories) for ESD-developed repos. External GitHub repos that are particularly relevant or useful:

| repo link                          | description                        |
|------------------------------------|------------------------------------|
| [dbdreader](https://github.com/smerckel/dbdreader) | Extract data from slocum binary files |
| [pyglider](https://github.com/c-proof/pyglider) | Convert datafiles from slocum and seaexplorer into netcdf |
| [GliderTools](https://github.com/GliderToolsCommunity/GliderTools) | Quality control and plot generic glider data |
| [IOOS qc](https://github.com/ioos/ioos_qc) | Apply IOOS QARTOD and other qc routines |
| [SOCIB](https://github.com/socib/glider_toolbox) | Process glider data in Matlab (not actively maintained) |
| [glider tools list](https://github.com/OceanGlidersCommunity/glider-tools-list) | [OceanGliders community](https://github.com/OceanGlidersCommunity) repository to list tools for processing glider data. Includes many of the tools listed above. |
